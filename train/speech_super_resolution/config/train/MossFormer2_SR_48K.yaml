#!/bin/bash 
mode: 'train'
network: "MossFormer2_SR_48K"  
config_json: "config/train/MossFormer2_SR_48K.json"
checkpoint_dir: "checkpoints/MossFormer2_SR_48K"

# FFT parameters
#sampling_rate: 48000
#win_type: 'hamming'
#win_len: 1920
#win_inc: 384
#fft_len: 1920
#num_mels: 60

# Train
tr_list: '/mnt/nas/mit_sg/shengkui.zhao/data_collection/clean_speech/sr_48kHz/emptychecked_new/tts_48k_44.1k_all_local.lst'
cv_list: '/mnt/nas/mit_sg/shengkui.zhao/data_collection/clean_speech/sr_48kHz/emptychecked_new/hifigan_validation_set.lst'
tt_list: 'None'
#init_learning_rate: 0.0005
#finetune_learning_rate: 0.00005
batch_size: 2
max_epoch: 100
#
weight_decay: 0.00001
clip_grad_norm: 10.
#
# # Log 
seed: 777
#
# # # dataset
#load_fbank: 1 #to return fbank from dataloader
#num_workers: 4
accu_grad: 1 # accumulate multiple batch sizes for one back-propagation updating
effec_batch_size: 8   # per GPU, only used if accu_grad is set to 1, must be multiple times of batch size
max_length: 4         # truncate the utterances in dataloader, in seconds 
